{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8b762fd-8271-466e-aafb-0826a967c2c8",
   "metadata": {},
   "source": [
    "[Текст ссылки](https://)### Выполнил: <font color='red'>Тижин Матвей Романович</font>\n",
    "\n",
    "### Тема: Web-сервер для обучения и использования ML-моделей\n",
    "\n",
    "#### Преподаватели: Роман Ищенко (roman.ischenko@gmail.com) и Илья Склонин\n",
    "\n",
    "**Дедлайн**: 18.01.2026\n",
    "\n",
    "**Среда выполнения**: Jupyter Notebook (Python 3.9+)\n",
    "\n",
    "#### Правила:\n",
    "\n",
    "Результаты выполнения задания:\n",
    "\n",
    "- архив со скриптами и файлами Dockerfile, который 1-2 команды позволяет развернуть сервер, решающий поставленные в задании задачи\n",
    "- Jupyter Notebook, где __весь код__ из скриптов дублируется (1 ячейка - 1 скрипт) с комментарием, содержащим информацию о том, из какого файла взят код и что верхнеуровнево этот код делает\n",
    "\n",
    "__Максимальное число баллов за задание - 35__.\n",
    "\n",
    "Готовое задание отправляется на почту преподавателя.\n",
    "\n",
    "Задание выполняется самостоятельно. Если какие-то студенты будут уличены в списывании, все они автоматически получат за эту работу 0 баллов. Если вы нашли в Интернете какой-то специфичный код, который собираетесь заимствовать, обязательно укажите это в задании - наверняка вы не единственный, кто найдёт и использует эту информацию.\n",
    "\n",
    "Удалять фрагменты формулировок заданий запрещается."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108b5e5d-86cb-4f3f-bca7-505b44a25d75",
   "metadata": {},
   "source": [
    "### Постановка задачи:\n",
    "\n",
    "**Серверная часть (22 балла):**\n",
    "\n",
    "- __В данной работе нужно написать многозадачный веб-сервер для обучения и инференса ML моделей. На старте сервер получает на вход (через .env) конфиг, в котором должны быть указаны 3 параметра: путь к директории для сохранения моделей внутри контейнера сервера, число ядер, доступных для обучения и максимальное число моделей, которые могут быть одновременно загружены для инференса.__\n",
    "\n",
    "\n",
    "- Сервер должен реализовывать следующие методы:\n",
    "    - `fit(X, y, config)` - обучить модель и сохранить на диск по указанным именем\n",
    "    - `predict(y, config)` - предсказать с помощью обученной и загруженной модели по её имени\n",
    "    - `load(config)` - загрузить обученную модель по её имени в режим инференса\n",
    "    - `unload(config)` - выгрузить загруженную модель по её имени\n",
    "    - `remove(config)` - удалить обученную модель с диска по её имени\n",
    "    - `remove_all()` - удалить все обученные модели с диска__\n",
    "\n",
    "\n",
    "- __Содержимое конфигов и форматы данных предлагается продумать и реализовать самостоятельно__\n",
    "- __Сервер должен иметь счётчик активных процессов. Максимальное число активных процессов соответствует числу ядер, переданному в конфиге при старте сервиса. Каждое обучение модели запускается в отдельном процессе и до своего завершения потребляет этот процесс. Один процесс всегда остаётся для сервера, в нём же загружаются и работают на инференс обученные модели__\n",
    "- __Сервер должен корректно обрабатывать все граничные случаи (запуск обучения без свободных ядер, запуск инфренса свыше лимита, запросы с несуществующими именами моделей, запросы с дублирующимися именами моделей)__\n",
    "- __В реализации должны поддерживаться не менее трёх дискриминативных моделей (т.е. принимающих на вход объекты и метки при обучении и предсказывающих метки для новых объектов)__\n",
    "- __Сервер должен быть реализован на FastAPI__\n",
    "- Проект разворачивается с помощью выбранной библиотеки управления виртуальными окружениями и технологии контейнеризации Docker\n",
    "\n",
    "**Клиентская часть (13 баллов):**\n",
    "\n",
    "- __Клиентская часть должна демонстрировать работу с реализованным сервером с помощью библиотек requests и aiohttp. Она может быть реализована непосредственно в Jupyter Notebook, с описанием ожидаемого действия, или в отдельном(-ых) скрипте(-ах), с дублированием в Jupyter Notebook (тогда работоспособность в ноутбуке не требуется). Далее описываются отдельные функции:\n",
    "- Код вызова последовательного вызова обучения как минимум двух (N) различных моделей с таким набором данных и параметрами, чтобы обучение одной модели длилось не менее 60 секунд.\n",
    "- Код вызова асинхронного вызова обучения как минимум двух различных моделей с демонстрацией, что работа выполняется в два (в N) раза быстрее\n",
    "- Асинхронный вызов нескольких предсказаний\n",
    "- Код демонстрации остальных функций сервера (загрузка, выгрузка, удаление)\n",
    "- Должны обрабатываться ошибки и исключения, возвращаемые сервером\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "437add58-ff69-42e1-afb3-f43644aec19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Файл: server/config.py\n",
    "# Описание: Этот скрипт отвечает за инициализацию настроек сервера. \n",
    "# Он считывает переменные из файла .env (путь к моделям, лимит ядер, лимит моделей в RAM) \n",
    "# с помощью библиотеки pydantic-settings. Эти настройки используются во всем приложении \n",
    "# для контроля потребления ресурсов.\n",
    "\n",
    "from pydantic_settings import BaseSettings, SettingsConfigDict\n",
    "\n",
    "class Settings(BaseSettings):\n",
    "    # Путь для сохранения моделей внутри контейнера\n",
    "    MODELS_PATH: str = \"saved_models\"\n",
    "    \n",
    "    # Число ядер, доступных для обучения (используется для семафора)\n",
    "    TRAINING_CORES: int = 4\n",
    "    \n",
    "    # Максимальное число моделей, которые могут быть одновременно загружены для инференса\n",
    "    MAX_INFERENCE_MODELS: int = 1\n",
    "\n",
    "    model_config = SettingsConfigDict(env_file=\".env\", env_file_encoding='utf-8')\n",
    "\n",
    "settings = Settings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93c3572d-9546-4bdb-933f-5f11716d73ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Файл: server/config_models.py\n",
    "# Описание: Скрипт содержит описание схем данных (Pydantic-моделей) для валидации входящих запросов.\n",
    "# Здесь реализована сложная логика валидации гиперпараметров для различных типов моделей:\n",
    "# LogisticRegression, RandomForest, XGBoost, LightGBM и CatBoost.\n",
    "# Используется Union и discriminator для автоматического определения типа модели в запросе /fit.\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Literal, Union, Optional\n",
    "\n",
    "class ModelNameConfig(BaseModel):\n",
    "    model_name: str = Field(..., max_length=50, description=\"Уникальное имя модели\")\n",
    "\n",
    "class LogisticRegressionConfig(ModelNameConfig):\n",
    "    model_type: Literal['LogisticRegression']\n",
    "    penalty: Literal['l1', 'l2', 'elasticnet', 'none'] = 'l2'\n",
    "    C: float = Field(1.0, gt=0)\n",
    "    solver: Literal['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'] = 'lbfgs'\n",
    "\n",
    "class RandomForestConfig(ModelNameConfig):\n",
    "    model_type: Literal['RandomForestClassifier']\n",
    "    n_estimators: int = Field(100, gt=0)\n",
    "    max_depth: Optional[int] = Field(None, ge=1)\n",
    "    min_samples_split: int = Field(2, ge=2)\n",
    "    criterion: Literal['gini', 'entropy', 'log_loss'] = 'gini'\n",
    "\n",
    "class XGBoostConfig(ModelNameConfig):\n",
    "    model_type: Literal['XGBClassifier']\n",
    "    n_estimators: int = Field(100, gt=0)\n",
    "    learning_rate: float = Field(0.1, gt=0)\n",
    "    max_depth: int = Field(3, ge=0)\n",
    "\n",
    "class LightGBMConfig(ModelNameConfig):\n",
    "    model_type: Literal['LGBMClassifier']\n",
    "    n_estimators: int = Field(100, gt=0)\n",
    "    learning_rate: float = Field(0.1, gt=0)\n",
    "    num_leaves: int = Field(31, gt=1)\n",
    "\n",
    "class CatBoostConfig(ModelNameConfig):\n",
    "    model_type: Literal['CatBoostClassifier']\n",
    "    iterations: int = Field(1000, gt=0)\n",
    "    learning_rate: float = Field(0.03, gt=0)\n",
    "    depth: int = Field(6, ge=1, le=16)\n",
    "    verbose: bool = False\n",
    "\n",
    "AnyModelConfig = Union[\n",
    "    LogisticRegressionConfig,\n",
    "    RandomForestConfig,\n",
    "    XGBoostConfig,\n",
    "    LightGBMConfig,\n",
    "    CatBoostConfig,\n",
    "]\n",
    "\n",
    "class FitRequest(BaseModel):\n",
    "    X: List[List[float]] = Field(..., description=\"Матрица признаков\")\n",
    "    y: List[int] = Field(..., description=\"Вектор меток\")\n",
    "    config: AnyModelConfig = Field(..., discriminator='model_type')\n",
    "\n",
    "class PredictRequest(BaseModel):\n",
    "    X: List[List[float]] = Field(...)\n",
    "    config: ModelNameConfig = Field(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7acf5218-fa24-4181-99d1-94de4982a987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Файл: server/main.py\n",
    "# Описание: Основной скрипт сервера на FastAPI. \n",
    "# Реализует логику:\n",
    "# 1. Lifespan: создание ProcessPoolExecutor для выноса обучения в отдельные процессы.\n",
    "# 2. Метод /fit: использует asyncio.Semaphore для контроля занятых ядер. Обучение происходит синхронно в пуле.\n",
    "# 3. Метод /load: контролирует лимит одновременно загруженных моделей в RAM (реестр LOADED_MODELS).\n",
    "# 4. Метод /predict: выполняет инференс на загруженных моделях.\n",
    "# 5. Методы управления диском: /remove и /remove_all для очистки сохраненных файлов.\n",
    "\n",
    "import time\n",
    "import os\n",
    "import shutil\n",
    "import asyncio\n",
    "import joblib\n",
    "from contextlib import asynccontextmanager\n",
    "from typing import List, Dict\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from fastapi import FastAPI, HTTPException\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from .config_models import FitRequest, PredictRequest, ModelNameConfig\n",
    "from .config import settings\n",
    "\n",
    "SUPPORTED_MODELS = {\n",
    "    'LogisticRegression': LogisticRegression,\n",
    "    'RandomForestClassifier': RandomForestClassifier,\n",
    "    'XGBClassifier': XGBClassifier,\n",
    "    'LGBMClassifier': LGBMClassifier,\n",
    "    'CatBoostClassifier': CatBoostClassifier,\n",
    "}\n",
    "\n",
    "training_semaphore: asyncio.Semaphore = None\n",
    "LOADED_MODELS = dict()\n",
    "\n",
    "def _train_model_sync(model_name, model_path, model_type, hyperparameters, X, y):\n",
    "    try:\n",
    "        if os.path.exists(model_path):\n",
    "            return f\"Модель по пути '{model_path}' уже существует.\"\n",
    "        if model_type not in SUPPORTED_MODELS:\n",
    "            return f\"Тип модели '{model_type}' не поддерживается.\"\n",
    "        \n",
    "        model_class = SUPPORTED_MODELS[model_type]   \n",
    "        model = model_class(**hyperparameters)\n",
    "        model.fit(X, y)\n",
    "        joblib.dump(model, model_path)\n",
    "        return f\"Модель {model_name} успешно сохранена в {model_path}\"\n",
    "    except Exception as e:\n",
    "        return f\"Ошибка при обучении: {e}\"\n",
    "\n",
    "@asynccontextmanager\n",
    "async def lifespan(app: FastAPI):\n",
    "    global training_semaphore\n",
    "    # Лимит активных процессов обучения задается через TRAINING_CORES\n",
    "    training_semaphore = asyncio.Semaphore(settings.TRAINING_CORES)\n",
    "    # Используем пул процессов для CPU-задач\n",
    "    app.state.process_pool = ProcessPoolExecutor(max_workers=settings.TRAINING_CORES)\n",
    "    print(f\"Сервер готов. Пул процессов: {settings.TRAINING_CORES}\")\n",
    "    yield\n",
    "    app.state.process_pool.shutdown(wait=True)\n",
    "\n",
    "app = FastAPI(title=\"ML Model Server\", lifespan=lifespan)\n",
    "\n",
    "@app.get('/')\n",
    "def read_root():\n",
    "    return {\"message\": \"Добро пожаловать на сервер для ML моделей!\"}\n",
    "\n",
    "@app.post('/fit')\n",
    "async def fit_model(request: FitRequest):\n",
    "    if training_semaphore.locked():\n",
    "        raise HTTPException(status_code=503, detail=\"Нет свободных ядер для обучения.\")\n",
    "    \n",
    "    os.makedirs(settings.MODELS_PATH, exist_ok=True)\n",
    "    model_name = request.config.model_name\n",
    "    model_path = os.path.join(settings.MODELS_PATH, f'{model_name}.joblib')\n",
    "    \n",
    "    hyperparams = request.config.model_dump(exclude={'model_name', 'model_type'})\n",
    "    \n",
    "    async with training_semaphore:\n",
    "        loop = asyncio.get_running_loop()\n",
    "        result = await loop.run_in_executor(\n",
    "            app.state.process_pool, _train_model_sync,\n",
    "            model_name, model_path, request.config.model_type, hyperparams, request.X, request.y\n",
    "        )\n",
    "\n",
    "    if result and \"Ошибка\" in result:\n",
    "        raise HTTPException(status_code=400, detail=result)\n",
    "    return {\"message\": \"Обучение завершено успешно.\", \"model_name\": model_name}\n",
    "\n",
    "@app.post('/predict')\n",
    "def predict(request: PredictRequest):\n",
    "    model_name = request.config.model_name\n",
    "    if model_name not in LOADED_MODELS:\n",
    "        raise HTTPException(status_code=404, detail=f\"Модель '{model_name}' не загружена в память.\")\n",
    "        \n",
    "    model = LOADED_MODELS[model_name]\n",
    "    try:\n",
    "        predictions = model.predict(request.X).tolist()\n",
    "        return {\"model_name\": model_name, \"predictions\": predictions}\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=400, detail=f\"Ошибка инференса: {e}\")\n",
    "\n",
    "@app.post('/load')\n",
    "def load_model(config: ModelNameConfig):\n",
    "    model_name = config.model_name\n",
    "    model_path = os.path.join(settings.MODELS_PATH, f'{model_name}.joblib')\n",
    "    \n",
    "    if model_name in LOADED_MODELS:\n",
    "        return {\"message\": f\"Модель {model_name} уже загружена\"}\n",
    "        \n",
    "    if len(LOADED_MODELS) >= settings.MAX_INFERENCE_MODELS:\n",
    "        raise HTTPException(status_code=409, detail=f\"Лимит RAM моделей достигнут ({settings.MAX_INFERENCE_MODELS}).\")\n",
    "\n",
    "    if not os.path.exists(model_path):\n",
    "        raise HTTPException(status_code=404, detail=\"Файл модели не найден на диске.\")\n",
    "\n",
    "    try:\n",
    "        LOADED_MODELS[model_name] = joblib.load(model_path)\n",
    "        return {\"message\": f\"Модель '{model_name}' успешно загружена.\"}\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=f\"Ошибка загрузки: {e}\")\n",
    "\n",
    "@app.post('/unload')\n",
    "def unload_model(config: ModelNameConfig):\n",
    "    model_name = config.model_name\n",
    "    if model_name in LOADED_MODELS:\n",
    "        del LOADED_MODELS[model_name]\n",
    "        return {\"message\": f\"Модель '{model_name}' выгружена.\"}\n",
    "    return {\"message\": \"Модель не была загружена.\"}\n",
    "\n",
    "@app.post('/remove')\n",
    "def remove_model(config: ModelNameConfig):\n",
    "    model_name = config.model_name\n",
    "    if model_name in LOADED_MODELS:\n",
    "        raise HTTPException(status_code=409, detail=\"Нельзя удалить загруженную модель.\")\n",
    "    \n",
    "    model_path = os.path.join(settings.MODELS_PATH, f'{model_name}.joblib')\n",
    "    if os.path.exists(model_path):\n",
    "        os.remove(model_path)\n",
    "        return {\"message\": f\"Файл {model_name} удален.\"}\n",
    "    raise HTTPException(status_code=404, detail=\"Файл не найден.\")\n",
    "\n",
    "@app.post('/remove_all')\n",
    "def remove_all_models():\n",
    "    if LOADED_MODELS:\n",
    "        raise HTTPException(status_code=409, detail=\"Выгрузите все модели перед очисткой диска.\")\n",
    "    if os.path.isdir(settings.MODELS_PATH):\n",
    "        shutil.rmtree(settings.MODELS_PATH)\n",
    "        os.makedirs(settings.MODELS_PATH, exist_ok=True)\n",
    "    return {\"message\": \"Все модели удалены с диска.\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566b2895-594e-4d24-8157-e8f08bf06229",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0333b22e-8137-47f0-98e5-9140cea5eea2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b82506-3e6c-4aef-8445-17118df2eb05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1062c248-c77c-4517-ae0d-ed7e2749325f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82c08152-4795-482a-85ac-a10d2284cad4",
   "metadata": {},
   "source": [
    "## Работа на стороне клиента"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d8dd1671-f5c5-4e91-adaa-acfda4d559de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import aiohttp\n",
    "import asyncio\n",
    "import json\n",
    "from sklearn.datasets import make_classification\n",
    "import time \n",
    "\n",
    "BASE_URL = \"http://127.0.0.1:8000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5d78ac45-f3b8-4eaf-bcaa-61717dae8fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Генерация завершена.\n"
     ]
    }
   ],
   "source": [
    "def generate_heavy_dataset(n_samples=15000, n_features=50, n_informative=30):\n",
    "    X, y = make_classification(\n",
    "        n_samples=n_samples,\n",
    "        n_features=n_features,\n",
    "        n_redundant=10,\n",
    "        n_classes=2,\n",
    "        random_state=42\n",
    "    )\n",
    "    print(\"Генерация завершена.\")\n",
    "    return X.tolist(), y.tolist()\n",
    "\n",
    "def check_response(response):\n",
    "    \"\"\"Проверяет HTTP-ответ и выводит результат.\"\"\"\n",
    "    if response.status_code == 200:\n",
    "        print(\"   Ответ сервера:\", response.json())\n",
    "    else:\n",
    "        print(f\"Ошибка: (Статус-код: {response.status_code})\")\n",
    "        try:\n",
    "            print(\"   Детали ошибки:\", response.json())\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"   Не удалось декодировать JSON из ответа.\")\n",
    "\n",
    "X_heavy, y_heavy = generate_heavy_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "eb1161a7-b8a7-48af-ad28-f3d8994ca169",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_configs = [\n",
    "    {\n",
    "        \"config\": {\n",
    "            \"model_name\": \"lgbm\",\n",
    "            \"model_type\": \"LGBMClassifier\",\n",
    "            \"n_estimators\": 200, \n",
    "            \"num_leaves\": 40\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"config\": {\n",
    "            \"model_name\": \"rf\",\n",
    "            \"model_type\": \"RandomForestClassifier\",\n",
    "            \"n_estimators\": 150, \n",
    "            \"max_depth\": 15\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60069ed-8548-4b7c-bf89-8138ac335010",
   "metadata": {},
   "source": [
    "__Асихронная отправка запросов на обучение с использованием `aiohttp`__.\n",
    "__Пример с эндпоинтом `/fit`__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ea2d0cbf-2811-432e-8b43-398e319eae2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Запуск последовательного (синхронного) обучения ---\n",
      "-> Отправка запроса для модели: 'lgbm'\n",
      "{'detail': \"Модель по пути 'saved_models/lgbm.joblib' уже существует.\"}\n",
      "-> Отправка запроса для модели: 'rf'\n",
      "{'detail': \"Модель по пути 'saved_models/rf.joblib' уже существует.\"}\n",
      "\n",
      "--- Последовательное обучение завершено за 2.5685 секунд ---\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Запуск последовательного (синхронного) обучения ---\")\n",
    "start_time_sequential = time.monotonic()\n",
    "\n",
    "for config in model_configs:\n",
    "    model_name = config['config']['model_name']\n",
    "    print(f\"-> Отправка запроса для модели: '{model_name}'\")\n",
    "    \n",
    "    # 1. Собираем payload для текущей модели\n",
    "    payload = {\n",
    "        \"X\": X_heavy,\n",
    "        \"y\": y_heavy,\n",
    "        **config\n",
    "    }\n",
    "    response = requests.post(f\"{BASE_URL}/fit\", json=payload)\n",
    "    print(response.json())\n",
    "    end_time_sequential = time.monotonic()\n",
    "print(f\"\\n--- Последовательное обучение завершено за {end_time_sequential - start_time_sequential:.4f} секунд ---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c66098fe-82ad-4d7f-bf00-51c114546e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Ответ сервера: {'message': \"Модель 'rf' уже выгружена из памяти.\"}\n",
      "   Ответ сервера: {'message': \"Модель 'lgbm' уже выгружена из памяти.\"}\n",
      "   Ответ сервера: {'message': \"Все модели из директории 'saved_models' были успешно удалены.\"}\n"
     ]
    }
   ],
   "source": [
    "response = requests.post(f\"{BASE_URL}/unload\", json={\"model_name\": \"rf\"})\n",
    "check_response(response)\n",
    "response = requests.post(f\"{BASE_URL}/unload\", json={\"model_name\": \"lgbm\"})\n",
    "check_response(response)\n",
    "response = requests.post(f\"{BASE_URL}/remove_all\")\n",
    "check_response(response )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "96167e79-586b-44d0-a1dc-1e971d0c4a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Отправка асинхронного запроса на обучение 'lgbm'...\n",
      "Отправка асинхронного запроса на обучение 'rf'...\n",
      "Ошибка при отправке задачи на обучение 'lgbm' (Статус: 400)\n",
      "   Детали: {'detail': 'Модель lgbm успешно загружена и находится в saved_models/lgbm.joblib'}\n",
      "Ошибка при отправке задачи на обучение 'rf' (Статус: 400)\n",
      "   Детали: {'detail': 'Модель rf успешно загружена и находится в saved_models/rf.joblib'}\n",
      "\n",
      "--- Последовательное обучение завершено за 67.7363 секунд ---\n"
     ]
    }
   ],
   "source": [
    "async def fit_model_async(session, payload):\n",
    "    \"\"\"Асинхронная функция для отправки запроса на обучение.\"\"\"\n",
    "    model_name = payload['config']['model_name']\n",
    "    print(f\"Отправка асинхронного запроса на обучение '{model_name}'...\")\n",
    "    \n",
    "    async with session.post(f\"{BASE_URL}/fit\", json=payload) as response:\n",
    "        if response.status == 200:\n",
    "            print(f\"Сервер принял задачу на обучение '{model_name}'\")\n",
    "            print(\"Ответ:\", await response.йjson())\n",
    "        else:\n",
    "            print(f\"Ошибка при отправке задачи на обучение '{model_name}' (Статус: {response.status})\")\n",
    "            print(\"   Детали:\", await response.json())\n",
    "\n",
    "async def main_fit(model_configs):\n",
    "    start_time_async = time.monotonic()\n",
    "    \n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = []\n",
    "        for config in model_configs:\n",
    "            payload = {\n",
    "                \"X\": X_heavy,\n",
    "                \"y\": y_heavy,\n",
    "                **config\n",
    "            }\n",
    "            task = asyncio.create_task(fit_model_async(session, payload))\n",
    "            tasks.append(task)\n",
    "        \n",
    "        await asyncio.gather(*tasks)\n",
    "\n",
    "    end_time_async = time.monotonic()\n",
    "\n",
    "start = time.monotonic()\n",
    "await main_fit(model_configs)\n",
    "end_time_sequential = time.monotonic()\n",
    "print(f\"\\n--- Последовательное обучение завершено за {end_time_sequential - start_time_sequential:.4f} секунд ---\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf52a9b-4547-4bda-aea8-3bc5bfd4a2bf",
   "metadata": {},
   "source": [
    "__Пример с эндпоинтом `/load`__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "41ec97d6-9fe5-4395-84b4-deaeed84c2cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Ответ сервера: {'message': \"Модель 'lgbm' успешно загружена в память.\"}\n",
      "Ошибка: (Статус-код: 409)\n",
      "   Детали ошибки: {'detail': \"Достигнут лимит одновременно загруженных моделей (1). Текущие загруженные модели: ['lgbm']. Выгрузите одну из них перед загрузкой новой.\"}\n"
     ]
    }
   ],
   "source": [
    "models_to_load = [\"lgbm\", \"rf\"]\n",
    "for model_name in models_to_load:\n",
    "    response = requests.post(f\"{BASE_URL}/load\", json={\"model_name\": model_name})\n",
    "    check_response(response )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da9f80b-da1c-4256-a41c-3e1b30257b0d",
   "metadata": {},
   "source": [
    "__Пример с эндпоинтом `/predict`__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "80a88265-bedd-4725-b1b4-f28874621b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "model_name = 'lgbm'\n",
    "\n",
    "predict_config = {\n",
    "    'X': X_heavy,\n",
    "    'config': {\n",
    "        'model_name': model_name\n",
    "    }\n",
    "}\n",
    "\n",
    "response = requests.post(f\"{BASE_URL}/predict\", json=predict_config)\n",
    "pred = response.json()['predictions']\n",
    "print(pred[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b703f33-b9e6-4322-b936-5a49769de83e",
   "metadata": {},
   "source": [
    "__Пример с эндпоинтом `/unload`__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "25011f73-3ea1-4c86-963c-bde54141b028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Ответ сервера: {'message': \"Модель 'rf' уже выгружена из памяти.\"}\n",
      "   Ответ сервера: {'message': \"Модель 'lgbm' уже выгружена из памяти.\"}\n"
     ]
    }
   ],
   "source": [
    "response = requests.post(f\"{BASE_URL}/unload\", json={\"model_name\": \"rf\"})\n",
    "check_response(response)\n",
    "response = requests.post(f\"{BASE_URL}/unload\", json={\"model_name\": \"lgbm\"})\n",
    "check_response(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee4262a-4ec6-4673-bb05-fba5c027959d",
   "metadata": {},
   "source": [
    "__Пример с эндпоинтом `/remove`__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "67524e92-b2bf-426f-a907-32d8058c98b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Ответ сервера: {'message': \"Файл модели 'lgbm' успешно удален с диска.\"}\n"
     ]
    }
   ],
   "source": [
    "response = requests.post(f\"{BASE_URL}/remove\", json={\"model_name\": \"lgbm\"})\n",
    "check_response(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0104b37a-8777-436a-a947-22b741da390a",
   "metadata": {},
   "source": [
    "__Пример с эндпоинтом `/remove_all`__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "210bf44c-2e5d-4356-a281-410e98b54655",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Ответ сервера: {'message': \"Все модели из директории 'saved_models' были успешно удалены.\"}\n"
     ]
    }
   ],
   "source": [
    "response = requests.post(f\"{BASE_URL}/remove_all\")\n",
    "check_response(response )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0adfe0-c3a3-4576-bee1-711d4c26d6c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (uv-task4)",
   "language": "python",
   "name": "task4-uv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
