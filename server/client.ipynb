{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d8dd1671-f5c5-4e91-adaa-acfda4d559de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import aiohttp\n",
    "import asyncio\n",
    "import json\n",
    "from sklearn.datasets import make_classification\n",
    "import time \n",
    "\n",
    "BASE_URL = \"http://127.0.0.1:8000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5d78ac45-f3b8-4eaf-bcaa-61717dae8fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Генерация завершена.\n"
     ]
    }
   ],
   "source": [
    "def generate_heavy_dataset(n_samples=15000, n_features=50, n_informative=30):\n",
    "    X, y = make_classification(\n",
    "        n_samples=n_samples,\n",
    "        n_features=n_features,\n",
    "        n_redundant=10,\n",
    "        n_classes=2,\n",
    "        random_state=42\n",
    "    )\n",
    "    print(\"Генерация завершена.\")\n",
    "    return X.tolist(), y.tolist()\n",
    "\n",
    "def check_response(response):\n",
    "    \"\"\"Проверяет HTTP-ответ и выводит результат.\"\"\"\n",
    "    if response.status_code == 200:\n",
    "        print(\"   Ответ сервера:\", response.json())\n",
    "    else:\n",
    "        print(f\"Ошибка: (Статус-код: {response.status_code})\")\n",
    "        try:\n",
    "            print(\"   Детали ошибки:\", response.json())\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"   Не удалось декодировать JSON из ответа.\")\n",
    "\n",
    "X_heavy, y_heavy = generate_heavy_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "eb1161a7-b8a7-48af-ad28-f3d8994ca169",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_configs = [\n",
    "    {\n",
    "        \"config\": {\n",
    "            \"model_name\": \"lgbm\",\n",
    "            \"model_type\": \"LGBMClassifier\",\n",
    "            \"n_estimators\": 200, \n",
    "            \"num_leaves\": 40\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"config\": {\n",
    "            \"model_name\": \"rf\",\n",
    "            \"model_type\": \"RandomForestClassifier\",\n",
    "            \"n_estimators\": 150, \n",
    "            \"max_depth\": 15\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60069ed-8548-4b7c-bf89-8138ac335010",
   "metadata": {},
   "source": [
    "__Асихронная отправка запросов на обучение с использованием `aiohttp`__.\n",
    "__Пример с эндпоинтом `/fit`__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ea2d0cbf-2811-432e-8b43-398e319eae2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Запуск последовательного (синхронного) обучения ---\n",
      "-> Отправка запроса для модели: 'lgbm'\n",
      "{'detail': \"Модель по пути 'saved_models/lgbm.joblib' уже существует.\"}\n",
      "-> Отправка запроса для модели: 'rf'\n",
      "{'detail': \"Модель по пути 'saved_models/rf.joblib' уже существует.\"}\n",
      "\n",
      "--- Последовательное обучение завершено за 2.5685 секунд ---\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Запуск последовательного (синхронного) обучения ---\")\n",
    "start_time_sequential = time.monotonic()\n",
    "\n",
    "for config in model_configs:\n",
    "    model_name = config['config']['model_name']\n",
    "    print(f\"-> Отправка запроса для модели: '{model_name}'\")\n",
    "    \n",
    "    # 1. Собираем payload для текущей модели\n",
    "    payload = {\n",
    "        \"X\": X_heavy,\n",
    "        \"y\": y_heavy,\n",
    "        **config\n",
    "    }\n",
    "    response = requests.post(f\"{BASE_URL}/fit\", json=payload)\n",
    "    print(response.json())\n",
    "    end_time_sequential = time.monotonic()\n",
    "print(f\"\\n--- Последовательное обучение завершено за {end_time_sequential - start_time_sequential:.4f} секунд ---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c66098fe-82ad-4d7f-bf00-51c114546e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Ответ сервера: {'message': \"Модель 'rf' уже выгружена из памяти.\"}\n",
      "   Ответ сервера: {'message': \"Модель 'lgbm' уже выгружена из памяти.\"}\n",
      "   Ответ сервера: {'message': \"Все модели из директории 'saved_models' были успешно удалены.\"}\n"
     ]
    }
   ],
   "source": [
    "response = requests.post(f\"{BASE_URL}/unload\", json={\"model_name\": \"rf\"})\n",
    "check_response(response)\n",
    "response = requests.post(f\"{BASE_URL}/unload\", json={\"model_name\": \"lgbm\"})\n",
    "check_response(response)\n",
    "response = requests.post(f\"{BASE_URL}/remove_all\")\n",
    "check_response(response )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "96167e79-586b-44d0-a1dc-1e971d0c4a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Отправка асинхронного запроса на обучение 'lgbm'...\n",
      "Отправка асинхронного запроса на обучение 'rf'...\n",
      "Ошибка при отправке задачи на обучение 'lgbm' (Статус: 400)\n",
      "   Детали: {'detail': 'Модель lgbm успешно загружена и находится в saved_models/lgbm.joblib'}\n",
      "Ошибка при отправке задачи на обучение 'rf' (Статус: 400)\n",
      "   Детали: {'detail': 'Модель rf успешно загружена и находится в saved_models/rf.joblib'}\n",
      "\n",
      "--- Последовательное обучение завершено за 67.7363 секунд ---\n"
     ]
    }
   ],
   "source": [
    "async def fit_model_async(session, payload):\n",
    "    \"\"\"Асинхронная функция для отправки запроса на обучение.\"\"\"\n",
    "    model_name = payload['config']['model_name']\n",
    "    print(f\"Отправка асинхронного запроса на обучение '{model_name}'...\")\n",
    "    \n",
    "    async with session.post(f\"{BASE_URL}/fit\", json=payload) as response:\n",
    "        if response.status == 200:\n",
    "            print(f\"Сервер принял задачу на обучение '{model_name}'\")\n",
    "            print(\"Ответ:\", await response.йjson())\n",
    "        else:\n",
    "            print(f\"Ошибка при отправке задачи на обучение '{model_name}' (Статус: {response.status})\")\n",
    "            print(\"   Детали:\", await response.json())\n",
    "\n",
    "async def main_fit(model_configs):\n",
    "    start_time_async = time.monotonic()\n",
    "    \n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = []\n",
    "        for config in model_configs:\n",
    "            payload = {\n",
    "                \"X\": X_heavy,\n",
    "                \"y\": y_heavy,\n",
    "                **config\n",
    "            }\n",
    "            task = asyncio.create_task(fit_model_async(session, payload))\n",
    "            tasks.append(task)\n",
    "        \n",
    "        await asyncio.gather(*tasks)\n",
    "\n",
    "    end_time_async = time.monotonic()\n",
    "\n",
    "start = time.monotonic()\n",
    "await main_fit(model_configs)\n",
    "end_time_sequential = time.monotonic()\n",
    "print(f\"\\n--- Последовательное обучение завершено за {end_time_sequential - start_time_sequential:.4f} секунд ---\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf52a9b-4547-4bda-aea8-3bc5bfd4a2bf",
   "metadata": {},
   "source": [
    "# __Пример с эндпоинтом `/load`__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "41ec97d6-9fe5-4395-84b4-deaeed84c2cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Ответ сервера: {'message': \"Модель 'lgbm' успешно загружена в память.\"}\n",
      "Ошибка: (Статус-код: 409)\n",
      "   Детали ошибки: {'detail': \"Достигнут лимит одновременно загруженных моделей (1). Текущие загруженные модели: ['lgbm']. Выгрузите одну из них перед загрузкой новой.\"}\n"
     ]
    }
   ],
   "source": [
    "models_to_load = [\"lgbm\", \"rf\"]\n",
    "for model_name in models_to_load:\n",
    "    response = requests.post(f\"{BASE_URL}/load\", json={\"model_name\": model_name})\n",
    "    check_response(response )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da9f80b-da1c-4256-a41c-3e1b30257b0d",
   "metadata": {},
   "source": [
    "__Пример с эндпоинтом `/predict`__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "80a88265-bedd-4725-b1b4-f28874621b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "model_name = 'lgbm'\n",
    "\n",
    "predict_config = {\n",
    "    'X': X_heavy,\n",
    "    'config': {\n",
    "        'model_name': model_name\n",
    "    }\n",
    "}\n",
    "\n",
    "response = requests.post(f\"{BASE_URL}/predict\", json=predict_config)\n",
    "pred = response.json()['predictions']\n",
    "print(pred[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b703f33-b9e6-4322-b936-5a49769de83e",
   "metadata": {},
   "source": [
    "__Пример с эндпоинтом `/unload`__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "25011f73-3ea1-4c86-963c-bde54141b028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Ответ сервера: {'message': \"Модель 'rf' уже выгружена из памяти.\"}\n",
      "   Ответ сервера: {'message': \"Модель 'lgbm' уже выгружена из памяти.\"}\n"
     ]
    }
   ],
   "source": [
    "response = requests.post(f\"{BASE_URL}/unload\", json={\"model_name\": \"rf\"})\n",
    "check_response(response)\n",
    "response = requests.post(f\"{BASE_URL}/unload\", json={\"model_name\": \"lgbm\"})\n",
    "check_response(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee4262a-4ec6-4673-bb05-fba5c027959d",
   "metadata": {},
   "source": [
    "__Пример с эндпоинтом `/remove`__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "67524e92-b2bf-426f-a907-32d8058c98b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Ответ сервера: {'message': \"Файл модели 'lgbm' успешно удален с диска.\"}\n"
     ]
    }
   ],
   "source": [
    "response = requests.post(f\"{BASE_URL}/remove\", json={\"model_name\": \"lgbm\"})\n",
    "check_response(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0104b37a-8777-436a-a947-22b741da390a",
   "metadata": {},
   "source": [
    "__Пример с эндпоинтом `/remove_all`__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "210bf44c-2e5d-4356-a281-410e98b54655",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Ответ сервера: {'message': \"Все модели из директории 'saved_models' были успешно удалены.\"}\n"
     ]
    }
   ],
   "source": [
    "response = requests.post(f\"{BASE_URL}/remove_all\")\n",
    "check_response(response )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0adfe0-c3a3-4576-bee1-711d4c26d6c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (uv-task4)",
   "language": "python",
   "name": "task4-uv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
