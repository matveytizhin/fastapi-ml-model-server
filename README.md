# Web-сервер для обучения и использования ML-моделей

**Выполнил:** <font color='red'>Тижин Матвей Романович</font>  
**Преподаватели:** Роман Ищенко, Илья Склонин  
**Дедлайн:** 18.01.2026  

## Постановка задачи (Задание)

### Серверная часть:
В данной работе реализован многозадачный веб-сервер для обучения и инференса ML моделей. На старте сервер получает на вход (через `.env`) конфиг, в котором указаны 3 параметра: путь к директории для сохранения моделей внутри контейнера сервера, число ядер, доступных для обучения и максимальное число моделей, которые могут быть одновременно загружены для инференса.

Сервер реализует следующие методы:
- `fit(X, y, config)` - обучить модель и сохранить на диск по указанным именем.
- `predict(y, config)` - предсказать с помощью обученной и загруженной модели по её имени.
- `load(config)` - загрузить обученную модель по её имени в режим инференса.
- `unload(config)` - выгрузить загруженную модель по её имени.
- `remove(config)` - удалить обученную модель с диска по её имени.
- `remove_all()` - удалить все обученные модели с диска.

**Технические требования:**
- Сервер имеет счётчик активных процессов. Максимальное число активных процессов соответствует числу ядер.
- Одно ядро всегда остаётся для сервера, в нём же загружаются и работают на инференс обученные модели.
- Каждое обучение модели запускается в отдельном процессе (`ProcessPoolExecutor`).
- Сервер корректно обрабатывает граничные случаи (запуск обучения без свободных ядер, запуск инференса свыше лимита, запросы с несуществующими/дублирующимися именами).
- Поддерживается не менее трех дискриминативных моделей.
- Стек: FastAPI, Scikit-learn, Docker.

### Клиентская часть:
Демонстрирует работу с реализованным сервером с помощью библиотек `requests` и `aiohttp`:
- Код последовательного вызова обучения (длительность одной модели ≥ 60 сек).
- Код асинхронного вызова обучения с демонстрацией ускорения работы.
- Асинхронный вызов нескольких предсказаний.
- Демонстрация загрузки, выгрузки и удаления.
- Обработка ошибок и исключений, возвращаемых сервером.

## Реализация проекта

Проект представляет собой масштабируемое решение для ML-инференса и обучения.

## Основные возможности

- **Параллельное обучение:** Использование пула процессов позволяет выполнять CPU-интенсивные задачи (обучение), не блокируя асинхронный событийный цикл FastAPI.
- **Управление ресурсами:** `asyncio.Semaphore` ограничивает число одновременно обучающихся моделей, а внутренний реестр контролирует лимит моделей в оперативной памяти (RAM).
- **Поддерживаемые алгоритмы:**
  - LogisticRegression
  - RandomForestClassifier
  - XGBClassifier
  - LGBMClassifier
  - CatBoostClassifier

## Конфигурация (.env)

Настройки задаются в файле `.env` в корне проекта:

```env
MODELS_PATH=saved_models
TRAINING_CORES=4
MAX_INFERENCE_MODELS=2
```
## API Эндпоинты

| Метод       | Путь           | Описание                                     |
|-------------|----------------|---------------------------------------------|
| POST        | `/fit`         | Обучение модели. Принимает данные и тип алгоритма. |
| POST        | `/load`        | Загрузка весов `.joblib` в память для предсказаний. |
| POST        | `/predict`     | Инференс (требует, чтобы модель была загружена). |
| POST        | `/unload`      | Выгрузка модели из памяти.                  |
| POST        | `/remove`      | Удаление файла конкретной модели.           |
| POST        | `/remove_all`  | Полная очистка хранилища моделей.           |

## Инструкция по запуску

### 1. Docker 

Команда поднимает сервер и выполняется из директории `fastapi-ml-model-server`. 

```bash
docker-compose up --build
```
Сервер будет доступен по адресу: http://localhost:8000

### 2. Локальный запуск

```bash
pip install -r requirements.txt
uvicorn server.main:app --host 127.0.0.1 --port 8000
```

## Демонстрация и документация

- **`client.ipynb`** — Клиентская часть. Содержит демонстрацию работы с API, асинхронные тесты через `aiohttp`, замеры времени обучения и примеры обработки ошибок (503 при занятых ядрах, 409 при конфликтах памяти).
- **`description_of_server_functionality.ipynb`** — Техническая документация. Содержит полный дубликат серверного кода с подробными комментариями к каждой логической части (API, конфигурация, модели данных).

## Структура проекта

- `server/` — исходный код FastAPI сервера.
- `saved_models/` — директория для персистентного хранения моделей.
- `Dockerfile` & `docker-compose.yml` — конфигурация контейнеров.
- `requirements.txt` — список зависимостей Python.
- `client.ipynb` — ноутбук для тестирования.
- `description_of_server_functionality.ipynb` — код сервера с комментариями.
